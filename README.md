## JSON FILE

The JSON file is basically separated in two keys:
"model" and "run".

### MODEL

Model defines everything related to the model architecture that will be executed.

#### CONFIGS
* batch defines the batch size.
* patch defines the shape of each patch (height, width and channels).
* recursive defines if the model will be recursive or not.
* levels defines the number of residues to be considered.
* loss defines the loss to be used for all the models.
* quantized_latent defines if the latent will be quantized.
* pixels_range defines the input and output ranges of the network.
    * In defines the range to which pixels in the default range \[0,1\] will be transformed before being processed by the network. It also defines the range to which pixels will be transformed after the images being processed by the network, so the range of values is keeped as desired (the loss is applied after the range transformation).
    * Out specifies the output range of the defined architecture. It is the counter dominion of the last activation function.
* lr_politics defines the optimizer and the learning rate to be used.
#### LOAD_MODEL
The folder containing the model to be loaded. If it's null (default value) no model will be loaded.
#### NEW_MODEL
* enc defines the layers of the encoder. 
    * The values available for "type" are those defined in the enums file's Klayers class (instantiate [Keras](https://www.tensorflow.org/versions/r2.0/api\_docs/python/tf/keras/layers) Layers and some
    custom layers). 
    * "filters" is the number of filters for the convolutional layer.
    * "kernel_size" is the size of the kernel.
    * "strides" is the stride used.
    * "activation" is the activation function
    * "padding" can be same or valid.
    * "name" is the name of this layer. Each layer must have a differente name.
    * "use_bias" boolean that if the bias for this layers will be used or not.
* dec defines the layers of the decoder. Works the same way as the enc.

### RUN

Run defines everything related to the execution of the model.

* out_folder: the folder where the output will be saved.
* num_ckpt: basically will define the number of iterations required until the model is saved.
* train: boolean defining the execution mode. If is false, a model must be passed in load_model (ckpt) to be executed.
* data_loader: define number of training iterations steps and the glob of the folder containing the images.

## EXECUTING THE SCRIPTS

### RUN_MODEL
To run the script just execute the following command:
```python3 run_model.py --config_file model_cfg.json```.
The script will be executed with the parameters passed in the json file.
If the execution model is "train" the model will be saved.
Otherwise, the images and latents generated by the model will be saved.

### PARSE_OUTPUT
To run the script just execute the following command:
```python3 parse_output.py --folder_to_parse folder```.
The folder is the output root generated by the model
executed in test mode.

## GENERATING THE DOCUMENTATION

### EPYDOC
First, install epydoc using ```sudo apt install python-epydoc```.
To generate the HTML documentation execute the following command:
```epydoc --parse-only ./*.py img_common/*.py utils_scripts/*.py -o docs```
It is possible to generate the PDF, using ```--pdf```.

## PREPARING A VIRTUALENV TO THE PROJECT IN LINUX / MACOS

This tutorial considers you've installed virtualenv in the system with:
pip3 install virtualenv 

It's interesting to create a virtualenv for the project. Enter the root of the
repository and Use the following command:
virtualenv venv --system-site-packages

It`ll create a folder named venv inside the root of the repository. The .gitignore
already ignorar a venv folder. So it's good to create it this way.

After that, use the following command to use the env:
source venv/bin/activate

With this, you`ll be using the venv libs. You can use the following command to
install the packages for the project:
pip3 install -r requirements.txt

In windows, the installation of virtualenv, the creation of the env and the
activation of the env are different. But the idea is the same.

### ATTENTION: 
if you're installing it in a computer where you do not have a gpu,
you'll have to edit the requirements.txt before. Erase de '-gpu':
Change 'tensorflow-gpu [..]' to 'tensorflow [...]'
